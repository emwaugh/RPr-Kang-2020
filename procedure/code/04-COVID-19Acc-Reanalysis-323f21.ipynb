{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: RP- Spatial Accessibility of COVID-19 Healthcare Resources in Illinois\n",
    "---\n",
    "\n",
    "### Original Replication (no results altering improvements have been made to the code)\n",
    "\n",
    "**Reproduction of**: Rapidly measuring spatial accessibility of COVID-19 healthcare resources: a case study of Illinois, USA\n",
    "\n",
    "Original study *by* Kang, J. Y., A. Michels, F. Lyu, Shaohua Wang, N. Agbodo, V. L. Freeman, and Shaowen Wang. 2020. Rapidly measuring spatial accessibility of COVID-19 healthcare resources: a case study of Illinois, USA. International Journal of Health Geographics 19 (1):1â€“17. DOI:[10.1186/s12942-020-00229-x](https://ij-healthgeographics.biomedcentral.com/articles/10.1186/s12942-020-00229-x).\n",
    "\n",
    "Reproduction Authors: Joe Holler, Kufre Udoh, Derrick Burt, Drew An-Pham, & Spring '21 Middlebury Geog 0323.\n",
    "\n",
    "Reproduction Materials Available at: [RP-Kang Repository](https://github.com/derrickburt/RP-Kang-Improvements)\n",
    "\n",
    "Created: `8 Jun 2021`\n",
    "Revised: `23 Aug 2021`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "To perform the ESFCA method, three types of data are required, as follows: (1) road network, (2) population, and (3) hospital information. The road network can be obtained from the [OpenStreetMap Python Library, called OSMNX](https://github.com/gboeing/osmnx). The population data is available on the [American Community Survey](https://data.census.gov/cedsci/deeplinks?url=https%3A%2F%2Ffactfinder.census.gov%2F&tid=GOVSTIMESERIES.CG00ORG01). Lastly, hosptial information is also publically available on the [Homeland Infrastructure Foundation-Level Data](https://hifld-geoplatform.opendata.arcgis.com/datasets/hospitals?geometry=-94.504%2C40.632%2C-80.980%2C43.486)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduction Intro\n",
    "\n",
    "to be written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materials  and Methods\n",
    "to be written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviations from & Improvements to the Original Code\n",
    "\n",
    "to be written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codes\n",
    "Import necessary libraries to run this model.\n",
    "See `requirements.txt` for the library versions used for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import re\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import folium\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Directories\n",
    "\n",
    "Because we have restructured the repository for replication, we need to check our working directory and make necessary adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to set work directory properly\n",
    "if os.path.basename(os.getcwd()) == 'code':\n",
    "    os.chdir('../../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Visualize Data\n",
    "\n",
    "### Population and COVID-19 Cases Data by County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Illinois census tracts geometry** can be downloaded from the United States Census Bureau's [Cartographic Boundary Shapefiles page](https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html)\n",
    "- Census Tracts --> Illinois\n",
    "\n",
    "**Demographic data** from the United States Census Bureau can be downloaded from the American Commnunity Survey [Advanced Search](https://data.census.gov/cedsci/table?text=b1001%20acs&t=Age%20and%20Sex&g=0400000US17%241400000&tid=ACSST5Y2019.S0101)\n",
    "- Topic --> Age and Sex\n",
    "- Geography --> All Census Tracts within Illinois\n",
    "- Product --> 2018: ACS 5-Year Estimates Subject Tables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Tracts Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Illinois census tract geometry\n",
    "illinois_tracts = gpd.read_file('./data/raw/public/PopDataBuffered/cb_2018_17_tract_500k.shp')\n",
    "\n",
    "# Preview tract geometry \n",
    "illinois_tracts.head()             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CRS for tract geometry\n",
    "print(illinois_tracts.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CRS to WGS84 EPSG:4326\n",
    "illinois_tracts = illinois_tracts.to_crs(epsg = 4326)\n",
    "\n",
    "# Select tracts from Cook and all adjacent counties \n",
    "illinois_tracts = illinois_tracts.loc[(illinois_tracts[\"COUNTYFP\"] == '031') |\n",
    "                                      (illinois_tracts[\"COUNTYFP\"] == '197') |\n",
    "                                      (illinois_tracts[\"COUNTYFP\"] == '043') |\n",
    "                                      (illinois_tracts[\"COUNTYFP\"] == '089') |\n",
    "                                      (illinois_tracts[\"COUNTYFP\"] == '097') |\n",
    "                                      (illinois_tracts[\"COUNTYFP\"] == '111')]\n",
    "# Preview illinois_tracts\n",
    "illinois_tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview tract outlines \n",
    "illinois_tracts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACS Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in demographic data \n",
    "# skiprows = [1,1] deletes first description row (1)\n",
    "demographic_data = pd.read_csv('./data/raw/public/PopDataBuffered/ACSDT5Y2018.B01001_data_with_overlays_2021-10-28T145639.csv', sep = ',', skiprows = [1,1])\n",
    "\n",
    "# Preview demographic data \n",
    "demographic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns for at-risk population (ages 50 - 85+) for both male and female\n",
    "at_risk_csv = demographic_data[[\"GEO_ID\",\n",
    "                                \"NAME\",\n",
    "                                \"B01001_001E\",\n",
    "                                \"B01001_016E\",\n",
    "                                \"B01001_017E\",\n",
    "                                \"B01001_018E\",\n",
    "                                \"B01001_019E\",\n",
    "                                \"B01001_020E\",\n",
    "                                \"B01001_021E\",\n",
    "                                \"B01001_022E\",\n",
    "                                \"B01001_023E\",\n",
    "                                \"B01001_024E\",\n",
    "                                \"B01001_025E\",\n",
    "                                \"B01001_040E\",\n",
    "                                \"B01001_041E\",\n",
    "                                \"B01001_042E\",\n",
    "                                \"B01001_043E\",\n",
    "                                \"B01001_044E\",\n",
    "                                \"B01001_045E\",\n",
    "                                \"B01001_046E\",\n",
    "                                \"B01001_047E\",\n",
    "                                \"B01001_048E\",\n",
    "                                \"B01001_049E\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of columns in dataframe\n",
    "len(at_risk_csv.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column by selecting and summing all columns that aren't geoid, name, and totalpop\n",
    "at_risk_csv['OverFifty'] = at_risk_csv.iloc[:, 3:23].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview new column\n",
    "at_risk_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to check if OverFifty totals match column totals\n",
    "check = demographic_data[[\"B01001_016E\",\n",
    "                          \"B01001_017E\",\n",
    "                          \"B01001_018E\",\n",
    "                          \"B01001_019E\",\n",
    "                          \"B01001_020E\",\n",
    "                          \"B01001_021E\",\n",
    "                          \"B01001_022E\",\n",
    "                          \"B01001_023E\",\n",
    "                          \"B01001_024E\",\n",
    "                          \"B01001_025E\",\n",
    "                          \"B01001_040E\",\n",
    "                          \"B01001_041E\",\n",
    "                          \"B01001_042E\",\n",
    "                          \"B01001_043E\",\n",
    "                          \"B01001_044E\",\n",
    "                          \"B01001_045E\",\n",
    "                          \"B01001_046E\",\n",
    "                          \"B01001_047E\",\n",
    "                          \"B01001_048E\",\n",
    "                          \"B01001_049E\"]]\n",
    "\n",
    "check.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename total population column\n",
    "at_risk_csv['TotalPop'] = at_risk_csv['B01001_001E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove age group columns\n",
    "at_risk_csv = at_risk_csv.drop(at_risk_csv.columns[2:23], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename GEOID column in at_risk_csv so it matches GEOID in illinois_tracts\n",
    "# Create a dictionary with old then replacement name\n",
    "new_names = {\"GEO_ID\" : \"AFFGEOID\"}\n",
    "at_risk_csv = at_risk_csv.rename(columns = new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview new column names\n",
    "at_risk_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Census Tract Geometry with Demographic Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join illinois_tracts and at_risk_csv, preview merged dataframe\n",
    "atrisk_data = illinois_tracts.merge(at_risk_csv, how='inner', on='AFFGEOID')\n",
    "atrisk_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the merge by ensuring that there are same number of points in each \n",
    "print(len(atrisk_data))\n",
    "print(len(illinois_tracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chicago Demographic Data \n",
    "The code chunk below obtains the original at-risk population data, which only includes people living within Chicago city limits. This data is unused in this reanalysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for at risk population (just within Chicago)\n",
    "# Unnecessary for reanalysis using surrounding counties \n",
    "original_atrisk_data = gpd.read_file('./data/raw/public/PopData/Chicago_Tract.shp')\n",
    "original_atrisk_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covid-19 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview data for covid cases\n",
    "covid_data = gpd.read_file('./data/raw/public/PopData/Chicago_ZIPCODE.shp')\n",
    "covid_data['cases'] = covid_data['cases']\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospital Data\n",
    "\n",
    "Note that 999 is treated as a \"NULL\"/\"NA\" so these hospitals are filtered out. This data contains the number of ICU beds and ventilators at each hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for hospitals\n",
    "hospitals = gpd.read_file('./data/raw/public/HospitalData/Chicago_Hospital_Info.shp')\n",
    "hospitals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and Plot Map of Hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hospitals in interactive folium map\n",
    "m = folium.Map(location = [41.85, -87.65], tiles = 'cartodbpositron', zoom_start = 10)\n",
    "for i in range(0, len(hospitals)):\n",
    "    folium.CircleMarker(\n",
    "      location = [hospitals.iloc[i]['Y'], hospitals.iloc[i]['X']],\n",
    "      popup = \"{}{}\\n{}{}\\n{}{}\".format('Hospital Name: ',hospitals.iloc[i]['Hospital'],\n",
    "                                      'ICU Beds: ',hospitals.iloc[i]['Adult ICU'],\n",
    "                                      'Ventilators: ', hospitals.iloc[i]['Total Vent']),\n",
    "      radius = 5,\n",
    "      color = 'grey',\n",
    "      fill = True,\n",
    "      fill_opacity = 0.6,\n",
    "      legend_name = 'Hospitals'\n",
    "    ).add_to(m)\n",
    "legend_html =   '''<div style=\"position: fixed; width: 20%; heigh: auto;\n",
    "                            bottom: 10px; left: 10px;\n",
    "                            solid grey; z-index:9999; font-size:14px;\n",
    "                            \">&nbsp; Legend<br>'''\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Plot Hexagon Grids (500-meter resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grid file and plot\n",
    "grid_file = gpd.read_file('./data/raw/public/GridFile/Chicago_Grid.shp')\n",
    "grid_file.plot(figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Street Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Read in Chicago street network (and pull from OSMnx drive if it doesn't already exist)\n",
    "if not os.path.exists(\"data/raw/private/Chicago_Network_Buffer.graphml\"):\n",
    "    print(\"Loading Chicago road network from OpenStreetMap. Please wait...\", flush=True)\n",
    "    G = ox.graph_from_place('Chicago', network_type='drive', buffer_dist=24140.2) # pulling the drive network the first time will take a while\n",
    "    print(\"Saving Chicago road network to raw/private/Chicago_Network_Buffer.graphml. Please wait...\", flush=True)\n",
    "    ox.save_graphml(G, 'raw/private/Chicago_Network_Buffer.graphml')\n",
    "    print(\"Data saved.\")\n",
    "else:\n",
    "    print(\"Loading Chicago road network from raw/private/Chicago_Network_Buffer.graphml. Please wait...\", flush=True)\n",
    "    G = ox.load_graphml('raw/private/Chicago_Network_Buffer.graphml', node_type=str)\n",
    "    print(\"Data loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Street Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ox.plot_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Turn nodes and edges into geodataframes\n",
    "nodes, edges = ox.graph_to_gdfs(G, nodes=True, edges=True)\n",
    "\n",
    "# Get unique counts of road segments for each speed limit\n",
    "print(edges['maxspeed'].value_counts())\n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Helper\" Functions\n",
    "\n",
    "The functions below are needed for our analysis later. Let's take a look!\n",
    "\n",
    "### network_setting\n",
    "\n",
    "Cleans the OSMnx network to work better with drive-time analysis.\n",
    "\n",
    "First, we remove all nodes with 0 outdegree because any hospital assigned to such a node would be unreachable from everywhere. Next, we remove small (under 10 node) *strongly connected components* to reduce erroneously small ego-centric networks. Lastly, we ensure that the max speed is set and in the correct units before calculating time.\n",
    "\n",
    "Args:\n",
    "\n",
    "* network: OSMnx network for the spatial extent of interest\n",
    "\n",
    "Returns:\n",
    "\n",
    "* OSMnx network: cleaned OSMnx network for the spatial extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_setting(network):\n",
    "    _nodes_removed = len([n for (n, deg) in network.out_degree() if deg == 0])\n",
    "    network.remove_nodes_from([n for (n, deg) in network.out_degree() if deg == 0])\n",
    "    for component in list(nx.strongly_connected_components(network)):\n",
    "        if len(component) < 10:\n",
    "            for node in component:\n",
    "                _nodes_removed += 1\n",
    "                network.remove_node(node)\n",
    "    for u, v, k, data in tqdm(G.edges(data = True, keys = True),position = 0):\n",
    "        if 'maxspeed' in data.keys():\n",
    "            speed_type = type(data['maxspeed'])\n",
    "            if (speed_type == str):\n",
    "                # Add in try/except blocks to catch maxspeed formats that don't fit Kang et al.'s cases\n",
    "                try:\n",
    "                    if len(data['maxspeed'].split(',')) == 2:\n",
    "                        data['maxspeed_fix'] = float(data['maxspeed'].split(',')[0])                  \n",
    "                    elif data['maxspeed'] == 'signals':\n",
    "                        data['maxspeed_fix'] = 35.0 # Drive speed setting as 35 miles\n",
    "                    else:\n",
    "                        data['maxspeed_fix'] = float(data['maxspeed'].split()[0])\n",
    "                except:\n",
    "                    data['maxspeed_fix'] = 35.0 # Miles\n",
    "            else:\n",
    "                try:\n",
    "                    data['maxspeed_fix'] = float(data['maxspeed'][0].split()[0])\n",
    "                except:\n",
    "                    data['maxspeed_fix'] = 35.0 # Miles\n",
    "        else:\n",
    "            data['maxspeed_fix'] = 35.0 # Miles\n",
    "        data['maxspeed_meters'] = data['maxspeed_fix'] * 26.8223 # Convert mile to meter\n",
    "        data['time'] = float(data['length'])/ data['maxspeed_meters']\n",
    "    print(\"Removed {} nodes ({:2.4f}%) from the OSMNX network\".format(_nodes_removed, _nodes_removed/float(network.number_of_nodes())))\n",
    "    print(\"Number of nodes: {}\".format(network.number_of_nodes()))\n",
    "    print(\"Number of edges: {}\".format(network.number_of_edges()))\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Street Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# G, hospitals, grid_file, pop_data = file_import (population_dropdown.value, place_dropdown.value)\n",
    "G = network_setting(G)\n",
    "# Create point geometries for each node in the graph, to make constructing catchment area polygons easier\n",
    "for node, data in G.nodes(data = True):\n",
    "    data['geometry'] = Point(data['x'], data['y'])\n",
    "# Modify code to react to processor dropdown (got rid of file_import function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Get unique counts for each road network\n",
    "# Turn nodes and edges in geodataframes\n",
    "nodes, edges = ox.graph_to_gdfs(G, nodes = True, edges = True)\n",
    "\n",
    "# Count\n",
    "print(edges['maxspeed_fix'].value_counts())\n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hospital_setting\n",
    "\n",
    "Finds the nearest OSMnx node for each hospital.\n",
    "\n",
    "Args:\n",
    "\n",
    "* hospital: GeoDataFrame of hospitals\n",
    "* G: OSMnx network\n",
    "\n",
    "Returns:\n",
    "\n",
    "* GeoDataFrame of hospitals with info on nearest OSMnx node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hospital_setting(hospitals, G):\n",
    "    # Create an empty column \n",
    "    hospitals['nearest_osm'] = None\n",
    "    # Append the neaerest osm column with each hospitals neaerest osm node\n",
    "    for i in tqdm(hospitals.index, desc = \"Find the nearest osm from hospitals\", position = 0):\n",
    "        hospitals['nearest_osm'][i] = ox.get_nearest_node(G, [hospitals['Y'][i], hospitals['X'][i]], method = 'euclidean') # find the nearest node from hospital location\n",
    "    print ('hospital setting is done')\n",
    "    return(hospitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pop_centroid\n",
    "\n",
    "Converts geodata to centroids\n",
    "\n",
    "Args:\n",
    "\n",
    "* pop_data: a GeodataFrame\n",
    "* pop_type: a string, either \"pop\" for general population or \"covid\" for COVID-19 case data\n",
    "\n",
    "Returns:\n",
    "\n",
    "* GeoDataFrame of centroids with population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To estimate the centroids of census tract / county\n",
    "def pop_centroid (pop_data, pop_type):\n",
    "    pop_data = pop_data.to_crs({'init': 'epsg:4326'})\n",
    "    # If pop is selected in dropdown, select at risk pop where population is greater than 0\n",
    "    if pop_type == \"pop\":\n",
    "        pop_data = pop_data[pop_data['OverFifty'] >= 0] \n",
    "    # If covid is selected in dropdown, select where covid cases are greater than 0\n",
    "    if pop_type == \"covid\":\n",
    "        pop_data = pop_data[pop_data['cases'] >= 0]\n",
    "    pop_cent = pop_data.centroid # it make the polygon to the point without any other information\n",
    "    # Convert to gdf\n",
    "    pop_centroid = gpd.GeoDataFrame()\n",
    "    i = 0\n",
    "    for point in tqdm(pop_cent, desc = 'Pop Centroid File Setting', position = 0):\n",
    "        if pop_type == \"pop\":\n",
    "            pop = pop_data.iloc[i]['OverFifty']\n",
    "            code = pop_data.iloc[i]['GEOID']\n",
    "        if pop_type == \"covid\":\n",
    "            pop = pop_data.iloc[i]['cases']\n",
    "            code = pop_data.iloc[i].ZCTA5CE10\n",
    "        pop_centroid = pop_centroid.append({'code':code,'pop': pop,'geometry': point}, ignore_index = True)\n",
    "        i = i+1\n",
    "    return(pop_centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate_catchment_area\n",
    "\n",
    "Calculates a catchment area of things within some distance of a point using a given metric.\n",
    "\n",
    "Function first creates an ego-centric subgraph on the NetworkX road network starting with the nearest OSM node for the hospital and going out to a given distance as measured by the distance unit. We then calculate the convex hull around the nodes in the ego-centric subgraph and make it a GeoPandas object.\n",
    "\n",
    "Args:\n",
    "\n",
    "* G: OSMNX network\n",
    "* nearest_osm: OSMNX road network node that is closest to the place of interest (hospital)\n",
    "* distance: the max distance to include in the catchment area\n",
    "* distance_unit: how we measure distance (used by ego_graph), we always use time\n",
    "\n",
    "Returns:\n",
    "\n",
    "* GeoDataFrame the catchment area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_catchment_area(G, nearest_osm, distance, distance_unit = \"time\"):\n",
    "    # Consutrct an ego graph based on distance unit for an input node\n",
    "    road_network = nx.ego_graph(G, nearest_osm, distance, distance = distance_unit) \n",
    "    # Create point geometries for all nodes in ego graph\n",
    "    nodes = [Point((data['x'], data['y'])) for node, data in road_network.nodes(data = True)]\n",
    "    # Create a single part geometry of all nodes\n",
    "    polygon = gpd.GeoSeries(nodes).unary_union.convex_hull ## to create convex hull\n",
    "    polygon = gpd.GeoDataFrame(gpd.GeoSeries(polygon)) ## change polygon to geopandas\n",
    "    polygon = polygon.rename(columns = {0:'geometry'}).set_geometry('geometry')\n",
    "    return polygon.copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hospital_measure_acc\n",
    "\n",
    "Measures the effect of a single hospital on the surrounding area. (Uses `calculate_catchment_area` or `djikstra_cca`)\n",
    "\n",
    "Args:\n",
    "\n",
    "* \\_thread\\_id: int used to keep track of which thread this is\n",
    "* hospital: Geopandas dataframe with information on a hospital\n",
    "* pop_data: Geopandas dataframe with population data\n",
    "* distances: Distances in time to calculate accessibility for\n",
    "* weights: how to weight the different travel distances\n",
    "\n",
    "Returns:\n",
    "\n",
    "* Tuple containing:\n",
    "    * Int (\\_thread\\_id)\n",
    "    * GeoDataFrame of catchment areas with key stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hospital_measure_acc (_thread_id, hospital, pop_data, distances, weights):\n",
    "    # weights = 1, 0.68, 0.22\n",
    "    # distances = 10 20 30\n",
    "    # Apply catchment calculation for each distance (10, 20, and 30 min)\n",
    "    polygons = []\n",
    "    for distance in distances:\n",
    "        # Append djikstra catchment calculation (uncomment to use)\n",
    "        polygons.append(calculate_catchment_area(G, hospital['nearest_osm'],distance))\n",
    "    # Clip the overlapping distance ploygons (create two donuts + hole)\n",
    "    for i in reversed(range(1, len(distances))):\n",
    "        polygons[i] = gpd.overlay(polygons[i], polygons[i-1], how = \"difference\")\n",
    "    \n",
    "    # Calculate accessibility measurements\n",
    "    num_pops = []\n",
    "    for j in pop_data.index:\n",
    "        point = pop_data['geometry'][j]\n",
    "        # Multiply polygons by weights\n",
    "        for k in range(len(polygons)):\n",
    "            if len(polygons[k]) > 0: # To exclude the weirdo (convex hull is not polygon)\n",
    "                if (point.within(polygons[k].iloc[0][\"geometry\"])):\n",
    "                    num_pops.append(pop_data['pop'][j] * weights[k])  \n",
    "    total_pop = sum(num_pops)\n",
    "    for i in range(len(distances)):\n",
    "        polygons[i]['time'] = distances[i]\n",
    "        polygons[i]['total_pop'] = total_pop\n",
    "        polygons[i]['hospital_icu_beds'] = float(hospital['Adult ICU'])/polygons[i]['total_pop'] # proportion of # of beds over pops in 10 mins\n",
    "        polygons[i]['hospital_vents'] = float(hospital['Total Vent'])/polygons[i]['total_pop'] # proportion of # of beds over pops in 10 mins\n",
    "        polygons[i].crs = { 'init' : 'epsg:4326'}\n",
    "        polygons[i] = polygons[i].to_crs({'init':'epsg:32616'})\n",
    "    print('\\rCatchment for hospital {:4.0f} complete'.format(_thread_id), end = \" \", flush = True)\n",
    "    return(_thread_id, [ polygon.copy(deep = True) for polygon in polygons ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measure_acc_par\n",
    "\n",
    "Parallel implementation of accessibility measurement.\n",
    "\n",
    "Args:\n",
    "\n",
    "* hospitals: Geodataframe of hospitals\n",
    "* pop_data: Geodataframe containing population data\n",
    "* network: OSMNX street network\n",
    "* distances: list of distances to calculate catchments for\n",
    "* weights: list of floats to apply to different catchments\n",
    "* num\\_proc: number of processors to use.\n",
    "\n",
    "Returns:\n",
    "\n",
    "* Geodataframe of catchments with accessibility statistics calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hospital_acc_unpacker(args):\n",
    "    return hospital_measure_acc(* args)\n",
    "\n",
    "# Parallel implementation fo previous function\n",
    "def measure_acc_par (hospitals, pop_data, network, distances, weights, num_proc = 4):\n",
    "    catchments = []\n",
    "    for distance in distances:\n",
    "        catchments.append(gpd.GeoDataFrame())\n",
    "    pool = mp.Pool(processes = num_proc)\n",
    "    hospital_list = [ hospitals.iloc[i] for i in range(len(hospitals)) ]\n",
    "    results = pool.map(hospital_acc_unpacker, zip(range(len(hospital_list)), hospital_list, itertools.repeat(pop_data), itertools.repeat(distances), itertools.repeat(weights)))\n",
    "    pool.close()\n",
    "    results.sort()\n",
    "    results = [ r[1] for r in results ]\n",
    "    for i in range(len(results)):\n",
    "        for j in range(len(distances)):\n",
    "            catchments[j] = catchments[j].append(results[i][j], sort = False)\n",
    "    return catchments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overlap_calc\n",
    "\n",
    "Calculates and aggregates accessibility statistics for one catchment on our grid file.\n",
    "\n",
    "Args:\n",
    "\n",
    "* \\_id: thread ID\n",
    "* poly: GeoDataFrame representing a catchment area\n",
    "* grid_file: a GeoDataFrame representing our grids\n",
    "* weight: the weight to applied for a given catchment\n",
    "* service_type: the service we are calculating for: ICU beds or ventilators\n",
    "\n",
    "Returns:\n",
    "\n",
    "* Tuple containing:\n",
    "    * thread ID\n",
    "    * Counter object (dictionary for numbers) with aggregated stats by grid ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def overlap_calc(_id, poly, grid_file, weight, service_type):\n",
    "    value_dict = Counter()\n",
    "    if type(poly.iloc[0][service_type]) != type(None):           \n",
    "        value = float(poly[service_type]) * weight\n",
    "        # Find polygons that overlap hex grids\n",
    "        intersect = gpd.overlay(grid_file, poly, how='intersection')\n",
    "        # Get the intersection's area\n",
    "        intersect['overlapped'] = intersect.area\n",
    "        # Divide overlapping area by total area to get percent\n",
    "        intersect['percent'] = intersect['overlapped']/intersect['area']\n",
    "        # Only choose intersecting catchments that make up greater than 50% of hexagon \n",
    "        intersect = intersect[intersect['percent'] >= 0.5]\n",
    "        # Pull id\n",
    "        intersect_region = intersect['id']\n",
    "        for intersect_id in intersect_region:\n",
    "            try:\n",
    "                value_dict[intersect_id] += value\n",
    "            except:\n",
    "                value_dict[intersect_id] = value\n",
    "    return(_id, value_dict)\n",
    "\n",
    "def overlap_calc_unpacker(args):\n",
    "    return overlap_calc(* args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overlapping_function\n",
    "\n",
    "Calculates how all catchment areas overlap with and affect the accessibility of each grid in our grid file.\n",
    "\n",
    "Args:\n",
    "\n",
    "* grid_file: GeoDataFrame of our grid\n",
    "* catchments: GeoDataFrame of our catchments\n",
    "* service_type: the kind of care being provided (ICU beds vs. ventilators)\n",
    "* weights: the weight to apply to each service type\n",
    "* num\\_proc: the number of processors\n",
    "\n",
    "Returns:\n",
    "\n",
    "* Geodataframe - grid\\_file with calculated stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_function (grid_file, catchments, service_type, weights, num_proc = 4):\n",
    "    grid_file[service_type] = 0\n",
    "    pool = mp.Pool(processes = num_proc)\n",
    "    acc_list = []\n",
    "    for i in range(len(catchments)):\n",
    "        acc_list.extend([ catchments[i][j:j+1] for j in range(len(catchments[i])) ])\n",
    "    acc_weights = []\n",
    "    for i in range(len(catchments)):\n",
    "        acc_weights.extend( [weights[i]]*len(catchments[i]) )\n",
    "    results = pool.map(overlap_calc_unpacker, zip(range(len(acc_list)), acc_list, itertools.repeat(grid_file), acc_weights, itertools.repeat(service_type)))\n",
    "    pool.close()\n",
    "    results.sort()\n",
    "    results = [ r[1] for r in results ]\n",
    "    service_values = results[0]\n",
    "    for result in results[1:]:\n",
    "        service_values += result\n",
    "    for intersect_id, value in service_values.items():\n",
    "        grid_file.loc[grid_file['id'] == intersect_id, service_type] += value\n",
    "    return(grid_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization\n",
    "\n",
    "Normalizes our result (Geodataframe) for a given resource (res)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization (result, res):\n",
    "    result[res] = (result[res] - min(result[res])) / (max(result[res]) - min(result[res]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Map Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_map(output_grid, base_map, hospitals, resource):\n",
    "    ax=output_grid.plot(column = resource, \n",
    "                        cmap = 'PuBuGn',\n",
    "                        figsize = (18,12), \n",
    "                        legend = True, \n",
    "                        zorder = 1)\n",
    "    # Next two lines set bounds for our x- and y-axes because it looks like there's a weird \n",
    "    # Point at the bottom left of the map that's messing up our frame (Maja)\n",
    "    ax.set_xlim([325000, 370000])\n",
    "    ax.set_ylim([550000, 600000])\n",
    "    hospitals.plot(ax = ax, \n",
    "                   markersize = 10, \n",
    "                   zorder = 1, \n",
    "                   c = 'black', \n",
    "                   label = 'hospitals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_map_classified(output_grid, base_map, hospitals, resource):\n",
    "    ax = output_grid.plot(column = resource, \n",
    "                        scheme = 'Equal_Interval', \n",
    "                        k = 5, \n",
    "                        linewidth = 0,\n",
    "                        cmap = 'Blues', \n",
    "                        figsize = (18,12), \n",
    "                        legend = True, \n",
    "                        label = \"Acc Measure\",\n",
    "                        zorder = 1)\n",
    "    # Next two lines set bounds for our x- and y-axes because it looks like there's a weird \n",
    "    # Point at the bottom left of the map that's messing up our frame (Maja)\n",
    "    ax.set_xlim([325000, 370000])\n",
    "    ax.set_ylim([550000, 600000])\n",
    "    hospitals.plot(ax = ax, \n",
    "                   markersize = 10, \n",
    "                   zorder = 2,\n",
    "                   c = 'black',\n",
    "                   legend = False,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ ME:\n",
    "\n",
    "This final section of code requires running and re-running certain cells depending on your inputs in the dropdown menu below. There are step-by-step provided instructions in the text cells, but the general idea is to run the code for each population and resource option before doing the final section. So, run through the code cell below up until the \"STOP HERE!\" for each iteration, and then move on to the final section.\n",
    "\n",
    "### Run the model\n",
    "\n",
    "Below you can customize the input of the model:\n",
    "\n",
    "* Processor - the number of processors to use\n",
    "* Region - the spatial extent of the measure\n",
    "* Population - the population to calculate the measure for\n",
    "* Resource - the hospital resource of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "processor_dropdown = ipywidgets.Dropdown( options = [(\"1\", 1), (\"2\", 2), (\"3\", 3), (\"4\", 4)],\n",
    "    value = 4, description = \"Processor: \")\n",
    "\n",
    "place_dropdown = ipywidgets.Dropdown( options=[(\"Chicago\", \"Chicago\"), (\"Illinois\",\"Illinois\")],\n",
    "    value = \"Chicago\", description = \"Region: \")\n",
    "\n",
    "population_dropdown = ipywidgets.Dropdown( options = [(\"Population at Risk\", \"pop\"), (\"COVID-19 Patients\", \"covid\") ],\n",
    "    value = \"pop\", description = \"Population: \")\n",
    "\n",
    "resource_dropdown = ipywidgets.Dropdown( options = [(\"ICU Beds\", \"hospital_icu_beds\"), (\"Ventilators\", \"hospital_vents\") ],\n",
    "    value = \"hospital_icu_beds\", description = \"Resource: \")\n",
    "\n",
    "display(processor_dropdown,place_dropdown,population_dropdown,resource_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "G = network_setting (G)\n",
    "# Modify code to select pop valuee based on dropdown menu choice\n",
    "if population_dropdown.value == \"pop\":\n",
    "    pop_data = pop_centroid(atrisk_data, population_dropdown.value)\n",
    "elif population_dropdown.value == \"covid\":\n",
    "    pop_data = pop_centroid(covid_data, population_dropdown.value)\n",
    "hospitals = hospital_setting(hospitals, G)\n",
    "distances = [10,20,30] # Distances in travel time\n",
    "weights = [1.0, 0.68, 0.22] # Weights where weights[0] is applied to distances[0]\n",
    "resources = [\"hospital_icu_beds\", \"hospital_vents\"] # resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "catchments = measure_acc_par(hospitals, pop_data, G, distances, weights, num_proc=processor_dropdown.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for j in range(len(catchments)):\n",
    "    catchments[j] = catchments[j][catchments[j][resource_dropdown.value] != float('inf')]\n",
    "result = overlapping_function(grid_file, catchments, resource_dropdown.value, weights, num_proc=processor_dropdown.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = normalization (result, resource_dropdown.value)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to geopackage -- will name the layer according the dropdown parameters\n",
    "result.to_file('data/derived/public/results_reanalysis_buffered.gpkg', \n",
    "                layer = '{}_{}'.format(population_dropdown.value,resource_dropdown.value), \n",
    "                driver = 'GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distribution of results\n",
    "\n",
    "Uncomment the final line of code to save the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the 'Hospital ICU Beds' selection of the population dropdown has been run, make a histogram\n",
    "if hasattr(result, 'hospital_icu_beds'):\n",
    "    result['hospital_icu_beds'].plot.hist(bins = 10)\n",
    "    plt.axvline(result['hospital_icu_beds'].mean(), color = 'k', linestyle = 'dashed', linewidth = 1)\n",
    "else:\n",
    "    print(\"Hospital ICU Beds have not been calculated yet.\\n\",\n",
    "          \"Try again after running the model with 'ICU Beds' selected as the resource.\")\n",
    "#plt.savefig('./results/figures/reproduction/{}_icu_histogram.png'.format(population_dropdown.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the final line of code to save the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the 'Ventilators' selection of the population dropdown has been run, make a histogram\n",
    "if hasattr(result, 'hospital_vents'):\n",
    "    result['hospital_vents'].plot.hist(bins = 10)\n",
    "    plt.axvline(result['hospital_vents'].mean(), color = 'k', linestyle = 'dashed', linewidth = 1)\n",
    "else:\n",
    "    print(\"Hospital ventilators have not been calculated yet.\\n\",\n",
    "      \"Try again after running the model with 'Ventilators' selected as the resource.\")\n",
    "#plt.savefig('./results/figures/reproduction/{}_vents_histogram.png'.format(population_dropdown.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and Save Raw Output to RP-Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals = hospitals.to_crs({'init': 'epsg:26971'})\n",
    "result = result.to_crs({'init': 'epsg:26971'})\n",
    "output_map(result, pop_data, hospitals, resource_dropdown.value)\n",
    "plt.legend(bbox_to_anchor = (.3, .1), prop = {'size': 15}, frameon = False);\n",
    "plt.savefig('./results/figures/reproduction/{}_{}_continuous.png'.format(population_dropdown.value, resource_dropdown.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and Save Classified Outputs to RP-Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_map_classified(result, pop_data, hospitals, resource_dropdown.value)\n",
    "plt.legend(bbox_to_anchor = (.3, .1), \n",
    "           prop = {'size': 15}, \n",
    "           frameon = False)\n",
    "plt.savefig('./results/figures/reproduction/{}_{}_classified.png'.format(population_dropdown.value, resource_dropdown.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOP HERE!\n",
    "\n",
    "If you have not run the model to calculate Ventilator and ICU accessibility scores for both COVID-19 and At Risk populations  (i.e: if you have not run the model four times)... Do that before you try to run the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with Original Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import study results to compare\n",
    "# hospital_i assumed to be for ICU and hospital_v assumed to be for ventilator\n",
    "# however it's unknown whether the population is the COVID-19 population or the AT RISK population\n",
    "fp = 'data/derived/public/Chicago_ACC.shp'\n",
    "og_result = gpd.read_file(fp)\n",
    "og_result.set_index(\"id\")\n",
    "og_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.set_index(\"id\")\n",
    "result_compare = result.join(og_result[[\"hospital_i\",\"hospital_v\"]])\n",
    "result_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate spearman rho for ICU beds\n",
    "icu_rho = stats.spearmanr(result_compare[[\"hospital_icu_beds\", \"hospital_i\"]])\n",
    "icu_rho = \"Rho = \" + str(round(icu_rho.correlation,3)) + \", pvalue = \" + str(icu_rho.pvalue)\n",
    "# Calculate spearman rho for Ventilators\n",
    "vents_rho = stats.spearmanr(result_compare[[\"hospital_vents\", \"hospital_v\"]])\n",
    "vents_rho = \"Rho = \" + str(round(vents_rho.correlation,3)) + \", pvalue = \" + str(vents_rho.pvalue)\n",
    "print(\"ICU:\", icu_rho,\"\\nVents:\", vents_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (14,4));\n",
    "\n",
    "axs[0].scatter(result_compare[[\"hospital_icu_beds\"]], result_compare[[\"hospital_i\"]], s = 1.5)\n",
    "axs[0].set_xlabel(\"Covid ICU - Reproduction\", labelpad = 5)\n",
    "axs[0].set_ylabel(\"Covid ICU - Original\", labelpad = 5)\n",
    "axs[0].text(.45, .08, icu_rho, fontsize = 8)\n",
    "axs[1].scatter(result_compare[[\"hospital_vents\"]], result_compare[[\"hospital_v\"]], s = 1.5)\n",
    "axs[1].set_xlabel(\"Covid Vents - Reproduction\", labelpad = 5)\n",
    "axs[1].set_ylabel(\"Covid Vents - Original\", labelpad = 5)\n",
    "axs[1].text(.45, .08, vents_rho, fontsize = 8)\n",
    "plt.savefig(\"./results/figures/reproduction/rho_correlation_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results & Discussion\n",
    "\n",
    "to be written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "to be written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Luo, W., & Qi, Y. (2009). An enhanced two-step floating catchment area (E2SFCA) method for measuring spatial accessibility to primary care physicians. Health & place, 15(4), 1100-1107."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
